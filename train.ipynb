{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KoSimCSE NLI 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from bert import BERT\n",
    "import pandas as pd\n",
    "from sentence_transformers import losses\n",
    "import math\n",
    "from sentence_transformers.readers import InputExample\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from torch.utils.data import DataLoader\n",
    "model_path = 'KoSimCSE-roberta-multitask/'\n",
    "data_path = '../Dataset/kb_dataset_nli.csv'\n",
    "\n",
    "df_nli = pd.read_csv(data_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyphothesis</th>\n",
       "      <th>label</th>\n",
       "      <th>premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>은행에서는 매주 최대 1천만원을 추첨하는 이벤트를 진행하고 있습니다.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>은행에서는 단 하루 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>은행에서는 단 3일 동안 최대 100만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 이벤트는 은행의 VIP 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>이 이벤트는 은행의 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1천만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이 이벤트는 은행의 직원에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1천만...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>이 이벤트는 은행의 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1천만...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하지 않고 문의할 수 있습니다.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 없습니다.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>은행 고객센터에서 문의하시면 자세한 내용을 안내해드립니다.</td>\n",
       "      <td>entailment</td>\n",
       "      <td>자세한 내용은 은행 고객센터나 홈페이지를 참고해주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>은행 고객센터에서는 다른 문제에 대해서도 도움을 받을 수 있습니다.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>자세한 내용은 은행 고객센터나 홈페이지를 참고해주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>은행 고객센터에서는 자세한 내용을 알려주지 않습니다.</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>자세한 내용은 은행 고객센터나 홈페이지를 참고해주세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1023 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hyphothesis          label  \\\n",
       "0                은행에서는 매주 최대 1천만원을 추첨하는 이벤트를 진행하고 있습니다.     entailment   \n",
       "1      은행에서는 단 하루 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.        neutral   \n",
       "2     은행에서는 단 3일 동안 최대 100만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.  contradiction   \n",
       "3     이 이벤트는 은행의 VIP 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여...     entailment   \n",
       "4     이 이벤트는 은행의 직원에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1천만...        neutral   \n",
       "...                                                 ...            ...   \n",
       "1018           스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하지 않고 문의할 수 있습니다.        neutral   \n",
       "1019              스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 없습니다.  contradiction   \n",
       "1020                   은행 고객센터에서 문의하시면 자세한 내용을 안내해드립니다.     entailment   \n",
       "1021              은행 고객센터에서는 다른 문제에 대해서도 도움을 받을 수 있습니다.        neutral   \n",
       "1022                      은행 고객센터에서는 자세한 내용을 알려주지 않습니다.  contradiction   \n",
       "\n",
       "                                                premise  \n",
       "0      은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.  \n",
       "1      은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.  \n",
       "2      은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있습니다.  \n",
       "3     이 이벤트는 은행의 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1천만...  \n",
       "4     이 이벤트는 은행의 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1천만...  \n",
       "...                                                 ...  \n",
       "1018              스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 있습니다.  \n",
       "1019              스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 있습니다.  \n",
       "1020                     자세한 내용은 은행 고객센터나 홈페이지를 참고해주세요.  \n",
       "1021                     자세한 내용은 은행 고객센터나 홈페이지를 참고해주세요.  \n",
       "1022                     자세한 내용은 은행 고객센터나 홈페이지를 참고해주세요.  \n",
       "\n",
       "[1023 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nli = df_nli.drop_duplicates(ignore_index=True)\n",
    "df_nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_nli_triplet_input_example(dataset):\n",
    "    ''' \n",
    "    Transform to Triplet format and InputExample\n",
    "    ''' \n",
    "    # transform to Triplet format\n",
    "    train_data = {}\n",
    "    def add_to_samples(sent1, sent2, label):\n",
    "        if sent1 not in train_data:\n",
    "            train_data[sent1] = {'contradiction': set(), 'entailment': set(), 'neutral': set()}\n",
    "        train_data[sent1][label].add(sent2)\n",
    "\n",
    "    for i, data in dataset.iterrows():\n",
    "        sent1 = data['hyphothesis'].strip()\n",
    "        sent2 = data['premise'].strip()\n",
    "        label = data['label']\n",
    "\n",
    "        add_to_samples(sent1, sent2, label)\n",
    "        add_to_samples(sent2, sent1, label) #Also add the opposite\n",
    "\n",
    "    # transform to InputExmaples\n",
    "    input_examples = []\n",
    "    for sent1, others in train_data.items():\n",
    "        if len(others['entailment']) > 0 and len(others['contradiction']) > 0:\n",
    "            input_examples.append(InputExample(texts=[sent1, random.choice(list(others['entailment'])), random.choice(list(others['contradiction']))]))\n",
    "            input_examples.append(InputExample(texts=[random.choice(list(others['entailment'])), sent1, random.choice(list(others['contradiction']))]))\n",
    "        \n",
    "    return input_examples\n",
    "\n",
    "\n",
    "\n",
    "nli_train_examples = make_nli_triplet_input_example(df_nli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    nli_train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embedding Model\n",
    "embedding_model = models.Transformer(\n",
    "    model_name_or_path=model_path, \n",
    "    max_seq_length=256,\n",
    "    do_lower_case=True\n",
    ")\n",
    "\n",
    "# Only use Mean Pooling -> Pooling all token embedding vectors of sentence.\n",
    "pooling_model = models.Pooling(\n",
    "    embedding_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True,\n",
    "    pooling_mode_cls_token=False,\n",
    "    pooling_mode_max_tokens=False,\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(modules=[embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "nli_num_epochs = 4\n",
    "train_batch_size = 32\n",
    "nli_model_save_path = 'output/training_nli_/'\n",
    "\n",
    "# Use MultipleNegativesRankingLoss\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model)\n",
    "# warmup steps\n",
    "warmup_steps = math.ceil(len(nli_train_examples) * nli_num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "\n",
    "# Training\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=nli_num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=nli_model_save_path,\n",
    "    use_amp=False       #Set to True, if your GPU supports FP16 operations\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KoSimCSE STS 추가 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../Dataset/kb_dataset_sts_all.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_model_save_path = 'output/training_nli_/'\n",
    "model = SentenceTransformer(nli_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': True}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sts_input_example(dataset):\n",
    "    ''' \n",
    "    Transform to InputExample\n",
    "    ''' \n",
    "    input_examples = []\n",
    "    for i, data in dataset.iterrows():\n",
    "        sentence1 = data['sent1']\n",
    "        sentence2 = data['sent2']\n",
    "        score = (data['score']) / 5.0  # normalize 0 to 5\n",
    "        input_examples.append(InputExample(texts=[sentence1, sentence2], label=score))\n",
    "\n",
    "    return input_examples\n",
    "\n",
    " \n",
    "  \n",
    "sts_train_examples = make_sts_input_example(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataloader\n",
    "train_dataloader = DataLoader(\n",
    "    sts_train_examples,\n",
    "    shuffle=True,\n",
    "    batch_size=16, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11220"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sts_train_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_num_epochs = 4\n",
    "train_batch_size = 32\n",
    "sts_model_save_path = 'output/training_sts_all_continue_training/'\n",
    "\n",
    "# Use CosineSimilarityLoss\n",
    "train_loss = losses.CosineSimilarityLoss(model=model)\n",
    "# warmup steps\n",
    "warmup_steps = math.ceil(len(sts_train_examples) * sts_num_epochs / train_batch_size * 0.1) #10% of train data for warm-up\n",
    "# Training\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=sts_num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=sts_model_save_path\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
