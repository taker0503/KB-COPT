{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT API를 활용하여 학습을 위한 STS dataset 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_makests= pd.read_csv('Dataset/kb_dataset_deidentified_oneline_overview_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 문장들 pair로 묶어서 tuple 형태로 저장\n",
    "sentence_pair_list = []\n",
    "for idx, row in df_makests.iterrows():\n",
    "    sentence1 = df_makests.iloc[idx].overview\n",
    "    num = idx+1\n",
    "    while num<len(df_makests):\n",
    "        sentence2 = df_makests.iloc[num].overview\n",
    "        sentence_pair_list.append((sentence1,sentence2))\n",
    "        num +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "sts_template = \"\"\"\n",
    "당신은 한국어에 능통한 문서 유사도 평가 AI입니다.\n",
    "아래 튜플 형식으로 제공된 문장들을 꼼꼼하게 읽은 후 각 문장들의 유사도를 평가해주세요.\n",
    "\n",
    "아래 나열된 지침을 기반으로 생성해주세요.\n",
    "1. 유사도는 의미론적인 측면에서 평가되어야 한다.\n",
    "2. 점수는 1점에서 5점 사이로 부여가 되며 첫번째 소수점까지 세밀하게 평가한다.\n",
    "3. 모든 평가는 일관성있게 측정되어야 한다.\n",
    "4. 결과는 아래와 같은 형식으로 제공되어야 한다.\n",
    "\n",
    "원하는 output 형식:\n",
    "{order}. {score}\n",
    "\n",
    "[평가 문장 리스트]\n",
    "{sentences}\n",
    "\"\"\"\n",
    "\n",
    "nli_template = \"\"\"\n",
    "당신은 한국어 NLI 데이터셋을 만드는 전문 AI입니다.\n",
    "아래 제공된 문장을 꼼꼼하게 읽은 후 해당 문장을 NLI 데이터셋 형태로 만들어주세요.\n",
    "\n",
    "[제공된 문장]\n",
    "{sentences}\n",
    "\n",
    "아래 나열된 지침을 기반으로 생성해주세요.\n",
    "1. NLI 데이터셋의 label은 (entailment, neutral, contradiction) triplet으로 구성됩니다.\n",
    " - entailment는 제공된 문장과 의미적으로 같은 문장을 의미합니다.\n",
    " - neutral은 제공된 문장과 의미적으로 관련 없는 문장을 의미합니다.\n",
    " - contradiction은 제공된 문장과 의미적으로 모순된 문장을 의미합니다.\n",
    "2. hyphothesis는 각 label에 해당하는 대표 문장으로 같은 주제 내에서 최대한 창의적으로 작성되어야 한다.\n",
    "3. 결과는 아래와 같은 json 형식으로 제공되어야 한다.\n",
    "\n",
    "원하는 output 형식:\n",
    "{\n",
    "\"premise\": {제공된문장},\n",
    "\"nli\" : [\n",
    "{\"hyphothesis\": {hyphothesis},\n",
    "\"label\": entailemnt},\n",
    "{\"hyphothesis\": {hyphothesis},\n",
    "\"label\": neutral},\n",
    "{\"hyphothesis\": {hyphothesis},\n",
    "\"label\": contradiction}\n",
    "]\n",
    "}\n",
    "\n",
    "\n",
    "올바른 NLI 데이터셋 예시:\n",
    "{\n",
    "\"premise\": \"은행의 이벤트에 참여하시려면 어플에서 행운의 상자를 열고 상품을 확인한 후 응모하셔야 합니다.\",\n",
    "\"nli\" : [\n",
    "{\"hyphothesis\": \"이벤트에 참여하려면 어플에서 행운 상자를 열어 상품을 확인한 후 응모하셔야 합니다.\",\n",
    "\"label\": \"entailment\"},\n",
    "{\"hyphothesis\": \"이벤트에 참여하시려면 행운 상자를 열고 상품을 확인한 후 응모하지 않으셔도 됩니다.\",\n",
    "\"label\": \"neutral\"},\n",
    "{\"hyphothesis\": \"이벤트에 참여하시려면 어플에서 럭키박스를 열지 않고 응모하셔야 합니다.\",\n",
    "\"label\": \"contradiction\"}\n",
    "]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "VALID_CHATGPT_MODELS = ['gpt-3.5-turbo', 'gpt-4']\n",
    "\n",
    "\n",
    "def get_instructions():\n",
    "    instructions_dict = {\n",
    "        'sts' : sts_template,\n",
    "        'nli' : nli_template\n",
    "    }\n",
    "    return instructions_dict\n",
    "\n",
    "def set_openai_key(key):\n",
    "    openai.api_key = key\n",
    "\n",
    "class AskQuestions():\n",
    "\n",
    "    def __init__(self, text, mode, model='gpt-3.5-turbo'):\n",
    "        self.text = text\n",
    "        self.model = model\n",
    "        self.mode = mode\n",
    "        self.instruction = get_instructions()\n",
    "\n",
    "    def ask_question(self):\n",
    "        instruction = self.instruction['sts'] if self.mode == 'sts' else self.instruction['nli']\n",
    "        chatgpt_messages = prepare_chatgpt_message(\n",
    "            instruction,\n",
    "            self.text\n",
    "        )\n",
    "        response = call_chatgpt(chatgpt_messages, model=self.model)\n",
    "\n",
    "        return response\n",
    "\n",
    "def prepare_chatgpt_message(task_prompt, text):\n",
    "    input_prompt = task_prompt.replace('{sentences}', text)\n",
    "    messages = [{\"role\": \"system\", \"content\": input_prompt}]\n",
    "    return messages\n",
    "\n",
    "def call_chatgpt(chatgpt_messages, model=\"gpt-3.5-turbo\"):\n",
    "    response = openai.ChatCompletion.create(model=model, messages=chatgpt_messages, temperature=0, max_tokens=1024)\n",
    "    reply = response['choices'][0]['message']['content']\n",
    "    return reply\n",
    "\n",
    "open_ai_key = 'chatgpt api key'\n",
    "set_openai_key(open_ai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 튜플 셔플 후 DataFrame 형태로 변환\n",
    "import random\n",
    "\n",
    "random.shuffle(sentence_pair_list)\n",
    "sentence_pair_df = pd.DataFrame(sentence_pair_list, columns=['sent1','sent2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 튜플 10개씩 chatgpt에 입력해주어 유사도 측정 \n",
    "def make_score_list(df):\n",
    "    score_list = [float(score[-3:]) for score in df.split('\\n')]\n",
    "    return score_list\n",
    "\n",
    "sts_df = pd.DataFrame(columns=['sent1','sent2','score'])\n",
    "error_idx_list = []\n",
    "for i in tqdm(range(0,len(sentence_pair_df),10)):\n",
    "    df = sentence_pair_df.iloc[i:i+10]\n",
    "    \n",
    "    sent1 = df.sent1.to_list()\n",
    "    sent2 = df.sent2.to_list()\n",
    "\n",
    "    example = [f'{idx+1}. {(sent1,sent2)}' for idx, (sent1, sent2) in enumerate(zip(sent1, sent2))]\n",
    "    example = '\\n'.join(example)\n",
    "\n",
    "    chat_try = AskQuestions(text=example, mode='sts')\n",
    "    response = chat_try.ask_question()\n",
    "    score_list = make_score_list(response)\n",
    "\n",
    "    if len(score_list) != 10:\n",
    "        error_idx_list.append(i)\n",
    "        print(f'index {idx} is not append.')\n",
    "    else:\n",
    "        new_row = pd.DataFrame({'sent1' : sent1, 'sent2' : sent2, 'score': score_list})\n",
    "        sts_df = pd.concat([sts_df,new_row])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STS dataset 저장\n",
    "sts_df = sts_df.reset_index(drop=True)\n",
    "sts_df.to_csv('Dataset/kb_dataset_sts.csv',index_label=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT API를 활용하여 NLI dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_makenli = pd.read_csv('Dataset/kb_dataset_all_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_makenli.columns = ['text']\n",
    "df_makenli = df_makenli[df_makenli.text.apply(lambda x: len(x)>=30)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이 이벤트는 **은행의 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이벤트 기간은 9월 28일부터 9월 30일까지이며, 당첨자 발표 및 경품 지급은 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경품은 **은행의 입출금이 자유로운 예금 계좌로 지급되며, 발표일로부터 10영업일 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이벤트에 참여하시려면 [Service]에서 럭키박스를 열고 상품을 확인한 후 응모하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>뱅킹서비스, 알림서비스, 생활/편의서비스, **카드만들기 등 다양한 서비스를 제공하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>또한 대출/외환서비스, 오픈뱅킹서비스 등도 이용할 수 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>스타뱅킹 길라잡이를 통해 더 편리하고 간편한 은행 업무를 경험해보세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>자세한 내용은 **은행 고객센터나 홈페이지를 참고해주세요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    **은행에서는 단 3일 동안 최대 1천만원을 추첨하는 럭키박스 이벤트를 진행하고 있...\n",
       "1    이 이벤트는 **은행의 고객에게만 제공되며, 참여하신 분들 중 한 분을 추첨하여 1...\n",
       "2    이벤트 기간은 9월 28일부터 9월 30일까지이며, 당첨자 발표 및 경품 지급은 1...\n",
       "3    경품은 **은행의 입출금이 자유로운 예금 계좌로 지급되며, 발표일로부터 10영업일 ...\n",
       "4    이벤트에 참여하시려면 [Service]에서 럭키박스를 열고 상품을 확인한 후 응모하...\n",
       "..                                                 ...\n",
       "337  뱅킹서비스, 알림서비스, 생활/편의서비스, **카드만들기 등 다양한 서비스를 제공하...\n",
       "338                또한 대출/외환서비스, 오픈뱅킹서비스 등도 이용할 수 있습니다.\n",
       "339            스타뱅킹 길라잡이를 통해 더 편리하고 간편한 은행 업무를 경험해보세요.\n",
       "340              스타뱅킹 길라잡이와 상담하거나 챗봇을 이용하여 문의할 수 있습니다.\n",
       "341                   자세한 내용은 **은행 고객센터나 홈페이지를 참고해주세요.\n",
       "\n",
       "[342 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_makenli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [20:55<00:00,  7.52s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "nli_json_list =[]\n",
    "err_idx_list = []\n",
    "\n",
    "for i in tqdm(range(175, len(df_makenli))):\n",
    "    df = df_makenli.iloc[i]\n",
    "    chat_try = AskQuestions(text=df.text, mode='nli')\n",
    "    response = chat_try.ask_question()\n",
    "    try:\n",
    "        res_json = json.loads(response)\n",
    "        nli_json_list.append(res_json)\n",
    "    except:\n",
    "        print(i)\n",
    "        err_idx_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(nli_json_list)\n",
    "df.to_csv('Dataset/kb_dataset_nli3.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Dataset/kb_dataset_nli.csv')\n",
    "df2 = pd.read_csv('Dataset/kb_dataset_nli2.csv')\n",
    "df3 = pd.read_csv('Dataset/kb_dataset_nli3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nli_all = pd.concat([df1,df2,df3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_dict_list = []\n",
    "def return_one(df):\n",
    "    nli = eval(df.nli)\n",
    "    for dict in nli:\n",
    "        nli_dict = dict\n",
    "        nli_dict['premise'] = df.premise\n",
    "        nli_dict_list.append(nli_dict)\n",
    "df_nli_all.apply(return_one, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_df = pd.DataFrame('Dataset/kb_dataset_nli.csv')\n",
    "nli_df.to_csv('Dataset/kb_dataset_nli.csv', index_label=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STS dataset Back translation 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Dataset/sts_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.concat([df['sent1'], df['sent2'], df['score']],axis=1)\n",
    "english_backtranslation_df = pd.concat([df['Augmented_sent1'], df['Augmented_sent2'], df['score']],axis=1)\n",
    "chinese_backtranslation_df = pd.concat([df['Augmented_sent3'], df['Augmented_sent4'], df['score']],axis=1)\n",
    "\n",
    "english_backtranslation_df.columns = ['sent1','sent2','score']\n",
    "chinese_backtranslation_df.columns = ['sent1','sent2','score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_backtranslation_df = pd.concat([original_df, english_backtranslation_df, chinese_backtranslation_df]).reset_index(drop=True)\n",
    "all_backtranslation_df.to_csv('Dataset/kb_dataset_sts_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
